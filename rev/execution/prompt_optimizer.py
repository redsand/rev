"""
Prompt Optimizer - Recommends improvements to user requests before execution.

This module provides request analysis and optimization capabilities that:
1. Analyzes the user's original request
2. Asks the LLM for recommendations to improve clarity and completeness
3. Optionally uses the improved prompt for planning

This helps with:
- Vague requests (clarify scope)
- Missing requirements (identify gaps)
- Better task decomposition (suggest structure)
- Catch issues early (before execution)
"""

import json
from typing import Dict, Any, Optional, Tuple
from rev.llm.client import ollama_chat


def should_optimize_prompt(user_request: str) -> bool:
    """
    Determine if a prompt should be optimized.

    Returns True if request might benefit from optimization:
    - Very short (< 10 words)
    - Vague language ("improve", "fix", "enhance" without specifics)
    - Asks for multiple unrelated things
    - Could be misunderstood
    """
    request_lower = user_request.lower()
    word_count = len(user_request.split())

    # Too vague indicators
    vague_keywords = [
        "improve", "fix", "make", "do", "help", "try",
        "enhance", "optimize", "better", "good", "nice"
    ]

    # Very short requests often lack detail
    if word_count < 10:
        return True

    # Count vague keywords without specifics
    vague_count = sum(1 for kw in vague_keywords if kw in request_lower)
    if vague_count > 0 and word_count < 30:
        return True

    # Multiple unrelated operations (check for "and" between different domains)
    if request_lower.count(" and ") > 2:
        return True

    return False


def get_prompt_recommendations(user_request: str) -> Optional[Dict[str, Any]]:
    """
    Ask LLM for recommendations to improve the user's request.

    Returns: Dict with original_prompt, recommendations, and suggested_improvement
    """
    optimization_prompt = f"""
You are a request clarification specialist. Your job is to help make user requests more clear and specific before they are executed.

USER REQUEST:
{user_request}

Analyze this request and provide:

1. **Clarity Assessment**: Is this request clear enough? What could be misunderstood?

2. **Missing Information**: What details are missing that would help understand the intent?

3. **Scope Check**: Is the scope too broad, too narrow, or unclear?

4. **Suggested Improvements**: Provide a specific, improved version of the request that is:
   - More specific and concrete
   - Includes important details
   - Clearly scoped
   - Follows best practices for code tasks

Format your response as JSON:
{{
  "clarity_score": 1-10,
  "is_vague": true/false,
  "potential_issues": ["issue1", "issue2"],
  "missing_info": ["missing1", "missing2"],
  "recommendations": ["rec1", "rec2"],
  "suggested_improvement": "improved request here",
  "reasoning": "why these improvements help"
}}
"""

    messages = [
        {"role": "user", "content": optimization_prompt}
    ]

    try:
        response = ollama_chat(messages, temperature=0.3)  # Lower temp for consistency

        if response and "message" in response:
            content = response["message"].get("content", "")
            if content:
                try:
                    # Extract JSON from response
                    json_start = content.find("{")
                    json_end = content.rfind("}") + 1
                    if json_start >= 0 and json_end > json_start:
                        json_str = content[json_start:json_end]
                        return json.loads(json_str)
                except (json.JSONDecodeError, ValueError):
                    pass

    except Exception as e:
        print(f"  âš ï¸ Error getting recommendations: {e}")

    return None


def prompt_optimization_dialog(
    user_request: str,
    interactive: bool = True
) -> Tuple[str, bool]:
    """
    Run the prompt optimization dialog with the user.

    Returns: (final_prompt, was_optimized)
    """
    print(f"\n{'='*70}")
    print("PROMPT OPTIMIZATION")
    print(f"{'='*70}")

    # Check if optimization is needed
    if not should_optimize_prompt(user_request):
        print(f"âœ“ Request appears clear. Proceeding without optimization.\n")
        return user_request, False

    print(f"ðŸ“‹ Analyzing request for potential improvements...\n")

    # Get recommendations
    recommendations = get_prompt_recommendations(user_request)

    if not recommendations:
        print("  âš ï¸ Could not generate recommendations. Using original request.\n")
        return user_request, False

    # Display analysis
    clarity_score = recommendations.get("clarity_score", 5)
    issues = recommendations.get("potential_issues", [])
    missing = recommendations.get("missing_info", [])
    improved = recommendations.get("suggested_improvement", user_request)

    print(f"ðŸ“Š Analysis Results:")
    print(f"   Clarity Score: {clarity_score}/10")

    if issues:
        print(f"\n   âš ï¸  Potential Issues:")
        for issue in issues:
            print(f"      - {issue}")

    if missing:
        print(f"\n   â“ Missing Information:")
        for item in missing:
            print(f"      - {item}")

    if recommendations.get("recommendations"):
        print(f"\n   ðŸ’¡ Recommendations:")
        for rec in recommendations["recommendations"]:
            print(f"      - {rec}")

    print(f"\nðŸ“ Suggested Improvement:")
    print(f"   {improved}\n")

    # Ask user what to do
    if not interactive:
        return improved, True

    print(f"{'='*70}")
    print("Options:")
    print("  [1] Use the suggested improvement")
    print("  [2] Keep the original request")
    print("  [3] Enter a custom request")
    print(f"{'='*70}\n")

    while True:
        try:
            choice = input("Choice [1-3]: ").strip()

            if choice == "1":
                print(f"\nâœ“ Using improved request.\n")
                return improved, True

            elif choice == "2":
                print(f"\nâœ“ Using original request.\n")
                return user_request, False

            elif choice == "3":
                custom = input("Enter your custom request: ").strip()
                if custom:
                    print(f"\nâœ“ Using custom request.\n")
                    return custom, True
                else:
                    print("Empty request. Please try again.\n")

            else:
                print("Invalid choice. Please enter 1, 2, or 3.\n")

        except (KeyboardInterrupt, EOFError):
            print("\n\nUsing original request.\n")
            return user_request, False


def optimize_prompt_if_needed(
    user_request: str,
    auto_optimize: bool = False
) -> Tuple[str, bool]:
    """
    Conditionally optimize a prompt.

    Args:
        user_request: The original user request
        auto_optimize: If True, automatically use improvements without asking

    Returns:
        (final_request, was_optimized)
    """
    if not should_optimize_prompt(user_request):
        return user_request, False

    return prompt_optimization_dialog(
        user_request,
        interactive=not auto_optimize
    )
