# Rev LLM Configuration Example
# Copy this file to .env and customize for your environment

# ============================================================================
# LLM MODEL CONFIGURATION
# ============================================================================

# Ollama server URL
OLLAMA_BASE_URL=http://localhost:11434

# Model to use (local or cloud)
# Examples: qwen3-coder:480b-cloud, llama3.1:8b, qwen2.5:14b
OLLAMA_MODEL=qwen3-coder:480b-cloud

# Model-specific settings (optional - override for different phases)
# REV_EXECUTION_MODEL=llama3.1:8b
# REV_PLANNING_MODEL=qwen2.5:14b
# REV_RESEARCH_MODEL=llama3.1:8b

# ============================================================================
# TOOL CALLING OPTIMIZATION (for improved accuracy with local models)
# ============================================================================

# Temperature (0.0-2.0) - Lower = more deterministic/accurate
# Recommended: 0.1 for tool calling, 0.7 for creative tasks
OLLAMA_TEMPERATURE=0.1

# Context window size (in tokens)
# 8192 = 8K (minimum), 16384 = 16K (recommended), 32768 = 32K (complex tasks)
OLLAMA_NUM_CTX=16384

# Top-p nucleus sampling (0.0-1.0)
OLLAMA_TOP_P=0.9

# Top-k vocabulary limiting
OLLAMA_TOP_K=40

# ============================================================================
# DEBUG AND LOGGING
# ============================================================================

# Enable LLM debug logging (shows prompts and parameters)
# Set to 1 to enable, 0 to disable
OLLAMA_DEBUG=0

# Log retention (days)
REV_LOG_RETENTION=7

# ============================================================================
# MODEL CAPABILITIES
# ============================================================================

# Does your model support tool/function calling?
# Set to "false" for models without native tool support
REV_MODEL_SUPPORTS_TOOLS=true

# Per-phase tool support overrides (if needed)
# REV_EXECUTION_SUPPORTS_TOOLS=true
# REV_PLANNING_SUPPORTS_TOOLS=true
# REV_RESEARCH_SUPPORTS_TOOLS=true

# ============================================================================
# RETRY CONFIGURATION
# ============================================================================

# Maximum retry attempts for LLM calls (0 = retry forever)
OLLAMA_MAX_RETRIES=0

# Retry forever regardless of max retries setting
OLLAMA_RETRY_FOREVER=1

# Initial backoff delay in seconds
OLLAMA_RETRY_BACKOFF_SECONDS=2.0

# Maximum backoff delay in seconds
OLLAMA_RETRY_BACKOFF_MAX_SECONDS=30.0

# Timeout multiplier cap for progressive timeout increases
OLLAMA_TIMEOUT_MAX_MULTIPLIER=3

# ============================================================================
# RESOURCE BUDGETS
# ============================================================================

# Maximum tokens per conversation
REV_MAX_TOKENS=2000000

# Maximum execution steps
REV_MAX_STEPS=500

# Maximum execution time (seconds)
REV_MAX_SECONDS=3600

# Maximum tasks in a plan
REV_MAX_PLAN_TASKS=12

# Per-task tool call limits
REV_MAX_READ_FILE_PER_TASK=999
REV_MAX_SEARCH_CODE_PER_TASK=999
REV_MAX_RUN_CMD_PER_TASK=999

# ============================================================================
# EXECUTION SETTINGS
# ============================================================================

# Maximum iterations per task
REV_MAX_TASK_ITER=45

# Maximum execution iterations
REV_MAX_EXEC_ITER=45

# Validation mode (off, targeted, comprehensive)
REV_VALIDATION_MODE=targeted

# Research depth (shallow, medium, deep)
REV_RESEARCH_DEPTH=medium

# ============================================================================
# PRIVATE MODE (disable public MCP servers for sensitive work)
# ============================================================================

# Enable private mode to disable public MCP servers
REV_PRIVATE_MODE=false

# ============================================================================
# MCP SERVER CONFIGURATION
# ============================================================================

# Enable/disable individual MCP servers
REV_MCP_MEMORY=true
REV_MCP_SEQUENTIAL_THINKING=true
REV_MCP_FETCH=true
REV_MCP_DEEPWIKI=true
REV_MCP_EXA_SEARCH=true
REV_MCP_SEMGREP=true
REV_MCP_CLOUDFLARE_DOCS=true
REV_MCP_LLMTEXT=true

# Optional MCP servers (require API keys)
# REV_MCP_BRAVE_SEARCH=false  # Requires BRAVE_API_KEY
# REV_MCP_GITHUB=false        # Requires GITHUB_TOKEN

# ============================================================================
# ADVANCED SETTINGS
# ============================================================================

# Code reuse preferences
REV_PREFER_REUSE=true
REV_WARN_NEW_FILES=true

# History configuration
REV_HISTORY_SIZE=100

# Paste detection thresholds
REV_PASTE_THRESHOLD=3
REV_PASTE_TIME_THRESHOLD=0.5

# ============================================================================
# QUICK CONFIGURATION PROFILES
# ============================================================================

# Profile: High Accuracy Tool Calling (default)
# OLLAMA_TEMPERATURE=0.1
# OLLAMA_NUM_CTX=16384

# Profile: Creative Tasks (documentation, commit messages)
# OLLAMA_TEMPERATURE=0.7
# OLLAMA_NUM_CTX=8192

# Profile: Complex Multi-Step Tasks
# OLLAMA_TEMPERATURE=0.1
# OLLAMA_NUM_CTX=32768

# Profile: Low Resource / Fast Execution
# OLLAMA_TEMPERATURE=0.2
# OLLAMA_NUM_CTX=8192
# OLLAMA_MODEL=llama3.1:8b

# Profile: Maximum Accuracy (critical tasks)
# OLLAMA_TEMPERATURE=0.0
# OLLAMA_NUM_CTX=32768
# OLLAMA_MODEL=qwen2.5:32b
